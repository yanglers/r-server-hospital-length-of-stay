{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e50443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Step 1 complete: data cleaned (numeric->mean, categorical->mode).\n",
      "Step 2 complete: standardized selected labs and created number_of_issues.\n",
      "No procedure column found among candidates; procedure-based stats disabled.\n",
      "Split complete: train=70000 rows, test=30000 rows.\n",
      "[RF] MAE=0.4940 | RMSE=0.7880 | R^2=0.8891\n",
      "[RF] OOB R^2=0.8905\n",
      "[GBT] MAE=0.3675 | RMSE=0.4854 | R^2=0.9579\n",
      "[FastTrees] MAE=0.3110 | RMSE=0.4310 | R^2=0.9668\n",
      "[NN] MAE=0.3253 | RMSE=0.4753 | R^2=0.9597\n",
      "[LIN] MAE=0.8449 | RMSE=1.1047 | R^2=0.7820\n",
      "\n",
      "Summary metrics (sorted by RMSE):\n",
      "       model       MAE      RMSE        R2\n",
      "2  FastTrees  0.311015  0.430963  0.966829\n",
      "3         NN  0.325252  0.475304  0.959653\n",
      "1        GBT  0.367469  0.485354  0.957928\n",
      "0         RF  0.493981  0.788006  0.889100\n",
      "4        LIN  0.844874  1.104719  0.782040\n",
      "\n",
      "Predictions tables written to ./predictions_sklearn_los/\n"
     ]
    }
   ],
   "source": [
    "# train_los_models.py\n",
    "\n",
    "# Step 0: Packages and setup\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    HistGradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "RANDOM_STATE = 100\n",
    "TRAIN_PCT = 0.70\n",
    "file_path = Path(\"..\") / \"Data\" / \"LengthOfStay.csv\"  # adjust if needed\n",
    "\n",
    "TARGET = \"lengthofstay\"\n",
    "ID_COL = \"eid\"\n",
    "DATE_COLS = [\"vdate\", \"discharged\"]\n",
    "DROP_FROM_FEATURES = [\"eid\", \"vdate\", \"discharged\", \"facid\"]  # match original exclusions\n",
    "\n",
    "# Columns standardized in the original notebook (Step 2)\n",
    "CONTINUOUS_TO_STANDARDIZE = [\n",
    "    \"hematocrit\",\n",
    "    \"neutrophils\",\n",
    "    \"sodium\",\n",
    "    \"glucose\",\n",
    "    \"bloodureanitro\",\n",
    "    \"creatinine\",\n",
    "    \"bmi\",\n",
    "    \"pulse\",\n",
    "    \"respiration\",\n",
    "]\n",
    "\n",
    "# Indicator columns used to compute \"number_of_issues\" (Step 2)\n",
    "ISSUE_INDICATORS = [\n",
    "    \"hemo\",\n",
    "    \"dialysisrenalendstage\",\n",
    "    \"asthma\",\n",
    "    \"irondef\",\n",
    "    \"pneum\",\n",
    "    \"substancedependence\",\n",
    "    \"psychologicaldisordermajor\",\n",
    "    \"depress\",\n",
    "    \"psychother\",\n",
    "    \"fibrosisandother\",\n",
    "    \"malnutrition\",\n",
    "]\n",
    "\n",
    "# Reasonable guesses for a \"procedure\" column\n",
    "PROCEDURE_COL_CANDIDATES = [\n",
    "    \"procedure\",\n",
    "    \"primaryprocedure\",\n",
    "    \"surgery\",\n",
    "    \"aprdrgdescription\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: evaluation\n",
    "# -----------------------------\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"[{model_name}] MAE={mae:.4f} | RMSE={rmse:.4f} | R^2={r2:.4f}\")\n",
    "    return {\"model\": model_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Load, type cast, clean NA\n",
    "# -----------------------------\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Parse dates\n",
    "for c in DATE_COLS:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "# Make sure indicator columns exist and are numeric\n",
    "present_issue_cols = [c for c in ISSUE_INDICATORS if c in df.columns]\n",
    "for c in present_issue_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Identify columns to clean (no NA cleaning on eid/lengthofstay/dates)\n",
    "protected = {ID_COL, TARGET, *DATE_COLS}\n",
    "cols_to_consider = [c for c in df.columns if c not in protected]\n",
    "\n",
    "num_cols_all = df[cols_to_consider].select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols_all = df[cols_to_consider].select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Fill numeric with mean\n",
    "if num_cols_all:\n",
    "    means = df[num_cols_all].mean(numeric_only=True)\n",
    "    df[num_cols_all] = df[num_cols_all].fillna(means)\n",
    "\n",
    "# Fill categorical with mode\n",
    "for c in cat_cols_all:\n",
    "    if df[c].isna().any():\n",
    "        mode_val = df[c].mode(dropna=True)\n",
    "        if not mode_val.empty:\n",
    "            df[c] = df[c].fillna(mode_val.iloc[0])\n",
    "        else:\n",
    "            df[c] = df[c].fillna(\"UNKNOWN\")\n",
    "\n",
    "print(\"Step 1 complete: data cleaned (numeric->mean, categorical->mode).\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Feature engineering\n",
    "# -----------------------------\n",
    "present_cont = [c for c in CONTINUOUS_TO_STANDARDIZE if c in df.columns]\n",
    "for c in present_cont:\n",
    "    std = df[c].std(ddof=0)\n",
    "    mean = df[c].mean()\n",
    "    df[c] = (df[c] - mean) / (std if std and std != 0 else 1.0)\n",
    "\n",
    "# number_of_issues = sum of indicator columns\n",
    "if present_issue_cols:\n",
    "    df[\"number_of_issues\"] = (\n",
    "        df[present_issue_cols]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .sum(axis=1)\n",
    "        .astype(int)\n",
    "    )\n",
    "    df[\"number_of_issues\"] = df[\"number_of_issues\"].astype(str)\n",
    "else:\n",
    "    df[\"number_of_issues\"] = \"0\"\n",
    "\n",
    "# Ensure target is numeric\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "\n",
    "print(\"Step 2 complete: standardized selected labs and created number_of_issues.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Procedure stats (for avg LoS, distribution, etc.)\n",
    "# -----------------------------\n",
    "PROC_COL = next((c for c in PROCEDURE_COL_CANDIDATES if c in df.columns), None)\n",
    "if PROC_COL:\n",
    "    proc_stats = df.groupby(PROC_COL)[TARGET].agg([\"mean\", \"std\", \"count\"])\n",
    "    print(f\"Using procedure column: {PROC_COL}\")\n",
    "else:\n",
    "    proc_stats = None\n",
    "    print(\"No procedure column found among candidates; procedure-based stats disabled.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare features/target and split\n",
    "# -----------------------------\n",
    "feature_cols = [c for c in df.columns if c not in set(DROP_FROM_FEATURES + [TARGET])]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=TRAIN_PCT, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Split complete: train={len(X_train)} rows, test={len(X_test)} rows.\")\n",
    "\n",
    "# ColumnTransformer: One-hot encode categoricals, pass numeric through\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Train & evaluate models\n",
    "# -----------------------------\n",
    "results = []\n",
    "oob_min_samples_split = int(max(2, round(sqrt(len(X_train)))))\n",
    "\n",
    "models = {\n",
    "    \"RF\": RandomForestRegressor(\n",
    "        n_estimators=40,\n",
    "        random_state=5,\n",
    "        oob_score=True,\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        min_samples_split=oob_min_samples_split,\n",
    "    ),\n",
    "    \"GBT\": GradientBoostingRegressor(\n",
    "        n_estimators=40,\n",
    "        learning_rate=0.3,\n",
    "        random_state=9,\n",
    "    ),\n",
    "    \"FastTrees\": HistGradientBoostingRegressor(\n",
    "        max_iter=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    \"NN\": MLPRegressor(\n",
    "        hidden_layer_sizes=(64, 64),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=500,\n",
    "        random_state=17,\n",
    "    ),\n",
    "    # Simple interpretable model for per-feature contributions\n",
    "    \"LIN\": LinearRegression(),\n",
    "}\n",
    "\n",
    "fitted_pipelines = {}\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    fitted_pipelines[name] = pipe\n",
    "\n",
    "    res = evaluate_model(y_test, y_pred, name)\n",
    "    if name == \"RF\" and hasattr(pipe.named_steps[\"model\"], \"oob_score_\"):\n",
    "        print(f\"[RF] OOB R^2={pipe.named_steps['model'].oob_score_:.4f}\")\n",
    "    results.append(res)\n",
    "\n",
    "# Collate results\n",
    "metrics_df = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "print(\"\\nSummary metrics (sorted by RMSE):\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Optionally persist models\n",
    "out_dir = Path(\"./models_sklearn_los\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "for name, pipe in fitted_pipelines.items():\n",
    "    joblib.dump(pipe, out_dir / f\"{name}_model.joblib\")\n",
    "\n",
    "# -----------------------------\n",
    "# Build predictions tables\n",
    "# -----------------------------\n",
    "def build_predictions_table(model_key=\"GBT\"):\n",
    "    assert model_key in fitted_pipelines, f\"Unknown model_key {model_key}\"\n",
    "    pipe = fitted_pipelines[model_key]\n",
    "\n",
    "    pred = pipe.predict(X_test)\n",
    "    pred_round = np.rint(pred).astype(int)\n",
    "\n",
    "    include_cols = [\n",
    "        \"eid\",\n",
    "        \"vdate\",\n",
    "        \"rcount\",\n",
    "        \"gender\",\n",
    "        \"dialysisrenalendstage\",\n",
    "        \"asthma\",\n",
    "        \"irondef\",\n",
    "        \"pneum\",\n",
    "        \"substancedependence\",\n",
    "        \"psychologicaldisordermajor\",\n",
    "        \"depress\",\n",
    "        \"psychother\",\n",
    "        \"fibrosisandother\",\n",
    "        \"malnutrition\",\n",
    "        \"hemo\",\n",
    "        \"hematocrit\",\n",
    "        \"neutrophils\",\n",
    "        \"sodium\",\n",
    "        \"glucose\",\n",
    "        \"bloodureanitro\",\n",
    "        \"creatinine\",\n",
    "        \"bmi\",\n",
    "        \"pulse\",\n",
    "        \"respiration\",\n",
    "        \"number_of_issues\",\n",
    "        \"secondarydiagnosisnonicd9\",\n",
    "        \"discharged\",\n",
    "        \"facid\",\n",
    "        \"lengthofstay\",\n",
    "    ]\n",
    "    if PROC_COL:\n",
    "        include_cols.append(PROC_COL)\n",
    "\n",
    "    present_cols = [c for c in include_cols if c in df.columns]\n",
    "\n",
    "    base = df.loc[X_test.index, present_cols].copy()\n",
    "\n",
    "    if \"vdate\" in base.columns and not np.issubdtype(base[\"vdate\"].dtype, np.datetime64):\n",
    "        base[\"vdate\"] = pd.to_datetime(base[\"vdate\"], errors=\"coerce\")\n",
    "\n",
    "    base[\"lengthofstay_Pred\"] = pred\n",
    "    base[\"lengthofstay_Pred_Rounded\"] = pred_round\n",
    "    if \"vdate\" in base.columns:\n",
    "        base[\"discharged_Pred\"] = base[\"vdate\"] + pd.to_timedelta(\n",
    "            base[\"lengthofstay_Pred_Rounded\"], unit=\"D\"\n",
    "        )\n",
    "    else:\n",
    "        base[\"discharged_Pred\"] = pd.NaT\n",
    "\n",
    "    # Add procedure-level context if available\n",
    "    if PROC_COL and proc_stats is not None and PROC_COL in base.columns:\n",
    "        base[\"procedure_AvgLoS\"] = base[PROC_COL].map(proc_stats[\"mean\"])\n",
    "        base[\"procedure_LoS_Std\"] = base[PROC_COL].map(proc_stats[\"std\"])\n",
    "\n",
    "        # Simple z-score based outlier flag\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            z = (base[\"lengthofstay_Pred\"] - base[\"procedure_AvgLoS\"]) / base[\n",
    "                \"procedure_LoS_Std\"\n",
    "            ]\n",
    "        base[\"procedure_LoS_Z\"] = z\n",
    "        base[\"possible_Outlier\"] = z.abs() > 2\n",
    "\n",
    "    # Ordering\n",
    "    order = [\n",
    "        \"eid\",\n",
    "        \"vdate\",\n",
    "        \"lengthofstay\",\n",
    "        \"lengthofstay_Pred\",\n",
    "        \"lengthofstay_Pred_Rounded\",\n",
    "        \"discharged_Pred\",\n",
    "    ]\n",
    "    if PROC_COL and PROC_COL in base.columns:\n",
    "        order.append(PROC_COL)\n",
    "        order += [\n",
    "            \"procedure_AvgLoS\",\n",
    "            \"procedure_LoS_Std\",\n",
    "            \"procedure_LoS_Z\",\n",
    "            \"possible_Outlier\",\n",
    "        ]\n",
    "    order += [c for c in present_cols if c not in order]\n",
    "    cols_final = [c for c in order if c in base.columns]\n",
    "    return base[cols_final]\n",
    "\n",
    "\n",
    "los_predictions_gbt = build_predictions_table(\"GBT\")\n",
    "los_predictions_rf = build_predictions_table(\"RF\")\n",
    "los_predictions_fast = build_predictions_table(\"FastTrees\")\n",
    "los_predictions_nn = build_predictions_table(\"NN\")\n",
    "los_predictions_lin = build_predictions_table(\"LIN\")\n",
    "\n",
    "# Save predictions\n",
    "out_dir_preds = Path(\"./predictions_sklearn_los\")\n",
    "out_dir_preds.mkdir(parents=True, exist_ok=True)\n",
    "los_predictions_gbt.to_csv(out_dir_preds / \"LoS_Predictions_GBT.csv\", index=False)\n",
    "los_predictions_rf.to_csv(out_dir_preds / \"LoS_Predictions_RF.csv\", index=False)\n",
    "los_predictions_fast.to_csv(out_dir_preds / \"LoS_Predictions_FastTrees.csv\", index=False)\n",
    "los_predictions_nn.to_csv(out_dir_preds / \"LoS_Predictions_NN.csv\", index=False)\n",
    "los_predictions_lin.to_csv(out_dir_preds / \"LoS_Predictions_LIN.csv\", index=False)\n",
    "\n",
    "print(\"\\nPredictions tables written to ./predictions_sklearn_los/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ayiyang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
