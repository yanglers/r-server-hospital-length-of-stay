{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e50443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 complete: data cleaned.\n",
      "Step 2 complete: standardized labs and created number_of_issues.\n",
      "No procedure column found among candidates.\n",
      "Split: train=70000, test=30000\n",
      "[LIN_OLS] MAE=0.8449 | RMSE=1.1047 | R^2=0.7820\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "[LIN_RIDGE] MAE=0.8449 | RMSE=1.1047 | R^2=0.7820\n",
      "[LIN_LASSO] MAE=0.8516 | RMSE=1.1205 | R^2=0.7758\n",
      "[LIN_ELASTIC] MAE=0.8479 | RMSE=1.1180 | R^2=0.7768\n",
      "[RF_100] MAE=0.4924 | RMSE=0.7858 | R^2=0.8897\n",
      "[RF_100] OOB R^2=0.8917\n",
      "[GBT_40] MAE=0.3675 | RMSE=0.4854 | R^2=0.9579\n",
      "[HGB_100] MAE=0.3110 | RMSE=0.4310 | R^2=0.9668\n",
      "[NN_64x2] MAE=0.3253 | RMSE=0.4753 | R^2=0.9597\n",
      "\n",
      "Summary metrics (sorted by RMSE):\n",
      "         model       MAE      RMSE        R2\n",
      "6      HGB_100  0.311015  0.430963  0.966829\n",
      "7      NN_64x2  0.325252  0.475304  0.959653\n",
      "5       GBT_40  0.367469  0.485354  0.957928\n",
      "4       RF_100  0.492421  0.785757  0.889732\n",
      "0      LIN_OLS  0.844874  1.104719  0.782040\n",
      "1    LIN_RIDGE  0.844871  1.104723  0.782038\n",
      "3  LIN_ELASTIC  0.847930  1.118032  0.776755\n",
      "2    LIN_LASSO  0.851624  1.120455  0.775787\n",
      "Saved 8 models to /Users/austinyang/r-server-hospital-length-of-stay/Python/models_sklearn_los\n",
      "Prediction tables written to /Users/austinyang/r-server-hospital-length-of-stay/Python/predictions_sklearn_los\n"
     ]
    }
   ],
   "source": [
    "# train_los_models.py\n",
    "# Train multiple LOS models and save them as sklearn pipelines.\n",
    "\n",
    "import os\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    HistGradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "RANDOM_STATE = 100\n",
    "TRAIN_PCT = 0.70\n",
    "file_path = Path(\"..\") / \"Data\" / \"LengthOfStay.csv\"  # adjust if needed\n",
    "\n",
    "TARGET = \"lengthofstay\"\n",
    "ID_COL = \"eid\"\n",
    "DATE_COLS = [\"vdate\", \"discharged\"]\n",
    "DROP_FROM_FEATURES = [\"eid\", \"vdate\", \"discharged\", \"facid\"]\n",
    "\n",
    "CONTINUOUS_TO_STANDARDIZE = [\n",
    "    \"hematocrit\",\n",
    "    \"neutrophils\",\n",
    "    \"sodium\",\n",
    "    \"glucose\",\n",
    "    \"bloodureanitro\",\n",
    "    \"creatinine\",\n",
    "    \"bmi\",\n",
    "    \"pulse\",\n",
    "    \"respiration\",\n",
    "]\n",
    "\n",
    "ISSUE_INDICATORS = [\n",
    "    \"hemo\",\n",
    "    \"dialysisrenalendstage\",\n",
    "    \"asthma\",\n",
    "    \"irondef\",\n",
    "    \"pneum\",\n",
    "    \"substancedependence\",\n",
    "    \"psychologicaldisordermajor\",\n",
    "    \"depress\",\n",
    "    \"psychother\",\n",
    "    \"fibrosisandother\",\n",
    "    \"malnutrition\",\n",
    "]\n",
    "\n",
    "PROCEDURE_COL_CANDIDATES = [\n",
    "    \"procedure\",\n",
    "    \"primaryprocedure\",\n",
    "    \"surgery\",\n",
    "    \"aprdrgdescription\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Utility\n",
    "# -----------------------------\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"[{model_name}] MAE={mae:.4f} | RMSE={rmse:.4f} | R^2={r2:.4f}\")\n",
    "    return {\"model\": model_name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Load, type cast, clean NA\n",
    "# -----------------------------\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Parse dates\n",
    "for c in DATE_COLS:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "# Ensure indicator columns numeric\n",
    "present_issue_cols = [c for c in ISSUE_INDICATORS if c in df.columns]\n",
    "for c in present_issue_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "protected = {ID_COL, TARGET, *DATE_COLS}\n",
    "cols_to_consider = [c for c in df.columns if c not in protected]\n",
    "\n",
    "num_cols_all = df[cols_to_consider].select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols_all = df[cols_to_consider].select_dtypes(\n",
    "    include=[\"object\", \"category\"]\n",
    ").columns.tolist()\n",
    "\n",
    "if num_cols_all:\n",
    "    means = df[num_cols_all].mean(numeric_only=True)\n",
    "    df[num_cols_all] = df[num_cols_all].fillna(means)\n",
    "\n",
    "for c in cat_cols_all:\n",
    "    if df[c].isna().any():\n",
    "        mode_val = df[c].mode(dropna=True)\n",
    "        df[c] = df[c].fillna(mode_val.iloc[0] if not mode_val.empty else \"UNKNOWN\")\n",
    "\n",
    "df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\")\n",
    "\n",
    "print(\"Step 1 complete: data cleaned.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Feature engineering\n",
    "# -----------------------------\n",
    "present_cont = [c for c in CONTINUOUS_TO_STANDARDIZE if c in df.columns]\n",
    "for c in present_cont:\n",
    "    mean = df[c].mean()\n",
    "    std = df[c].std(ddof=0)\n",
    "    df[c] = (df[c] - mean) / (std if std else 1.0)\n",
    "\n",
    "if present_issue_cols:\n",
    "    df[\"number_of_issues\"] = (\n",
    "        df[present_issue_cols]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .sum(axis=1)\n",
    "        .astype(int)\n",
    "        .astype(str)\n",
    "    )\n",
    "else:\n",
    "    df[\"number_of_issues\"] = \"0\"\n",
    "\n",
    "print(\"Step 2 complete: standardized labs and created number_of_issues.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Procedure stats (for reference / later use)\n",
    "# -----------------------------\n",
    "PROC_COL = next((c for c in PROCEDURE_COL_CANDIDATES if c in df.columns), None)\n",
    "if PROC_COL:\n",
    "    proc_stats = df.groupby(PROC_COL)[TARGET].agg([\"mean\", \"std\", \"count\"])\n",
    "    print(f\"Using procedure column: {PROC_COL}\")\n",
    "else:\n",
    "    proc_stats = None\n",
    "    print(\"No procedure column found among candidates.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare features/target and split\n",
    "# -----------------------------\n",
    "feature_cols = [c for c in df.columns if c not in set(DROP_FROM_FEATURES + [TARGET])]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=TRAIN_PCT, random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Split: train={len(X_train)}, test={len(X_test)}\")\n",
    "\n",
    "# Preprocessor\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", ohe, cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Train many models\n",
    "# -----------------------------\n",
    "results = []\n",
    "oob_min_samples_split = int(max(2, round(sqrt(len(X_train)))))\n",
    "\n",
    "models = {\n",
    "    # Linear family (per-feature contributions via coef_)\n",
    "    \"LIN_OLS\": LinearRegression(),\n",
    "    \"LIN_RIDGE\": Ridge(alpha=1.0),\n",
    "    \"LIN_LASSO\": Lasso(alpha=0.01, max_iter=5000),\n",
    "    \"LIN_ELASTIC\": ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=5000),\n",
    "\n",
    "    # Tree-based models (feature_importances_)\n",
    "    \"RF_100\": RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=5,\n",
    "        oob_score=True,\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        min_samples_split=oob_min_samples_split,\n",
    "    ),\n",
    "    \"GBT_40\": GradientBoostingRegressor(\n",
    "        n_estimators=40,\n",
    "        learning_rate=0.3,\n",
    "        random_state=9,\n",
    "    ),\n",
    "    \"HGB_100\": HistGradientBoostingRegressor(\n",
    "        max_iter=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "\n",
    "    # Neural net / black-box\n",
    "    \"NN_64x2\": MLPRegressor(\n",
    "        hidden_layer_sizes=(64, 64),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=500,\n",
    "        random_state=17,\n",
    "    ),\n",
    "}\n",
    "\n",
    "fitted_pipelines = {}\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    fitted_pipelines[name] = pipe\n",
    "\n",
    "    res = evaluate_model(y_test, y_pred, name)\n",
    "    if name.startswith(\"RF\") and hasattr(pipe.named_steps[\"model\"], \"oob_score_\"):\n",
    "        print(f\"[{name}] OOB R^2={pipe.named_steps['model'].oob_score_:.4f}\")\n",
    "    results.append(res)\n",
    "\n",
    "metrics_df = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "print(\"\\nSummary metrics (sorted by RMSE):\")\n",
    "print(metrics_df)\n",
    "\n",
    "# -----------------------------\n",
    "# Save models\n",
    "# -----------------------------\n",
    "out_dir = Path(\"./models_sklearn_los\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "for name, pipe in fitted_pipelines.items():\n",
    "    joblib.dump(pipe, out_dir / f\"{name}_model.joblib\")\n",
    "print(f\"Saved {len(fitted_pipelines)} models to {out_dir.resolve()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: build predictions tables for a few models\n",
    "# -----------------------------\n",
    "def build_predictions_table(model_key: str):\n",
    "    assert model_key in fitted_pipelines, f\"Unknown model_key {model_key}\"\n",
    "    pipe = fitted_pipelines[model_key]\n",
    "\n",
    "    pred = pipe.predict(X_test)\n",
    "    pred_round = np.rint(pred).astype(int)\n",
    "\n",
    "    include_cols = [\n",
    "        \"eid\",\n",
    "        \"vdate\",\n",
    "        \"rcount\",\n",
    "        \"gender\",\n",
    "        \"discharged\",\n",
    "        \"facid\",\n",
    "        \"lengthofstay\",\n",
    "    ]\n",
    "    if PROC_COL:\n",
    "        include_cols.append(PROC_COL)\n",
    "\n",
    "    present_cols = [c for c in include_cols if c in df.columns]\n",
    "    base = df.loc[X_test.index, present_cols].copy()\n",
    "\n",
    "    if \"vdate\" in base.columns:\n",
    "        base[\"vdate\"] = pd.to_datetime(base[\"vdate\"], errors=\"coerce\")\n",
    "\n",
    "    base[\"lengthofstay_Pred\"] = pred\n",
    "    base[\"lengthofstay_Pred_Rounded\"] = pred_round\n",
    "    if \"vdate\" in base.columns:\n",
    "        base[\"discharged_Pred\"] = base[\"vdate\"] + pd.to_timedelta(\n",
    "            base[\"lengthofstay_Pred_Rounded\"], unit=\"D\"\n",
    "        )\n",
    "    else:\n",
    "        base[\"discharged_Pred\"] = pd.NaT\n",
    "\n",
    "    if PROC_COL and proc_stats is not None and PROC_COL in base.columns:\n",
    "        base[\"procedure_AvgLoS\"] = base[PROC_COL].map(proc_stats[\"mean\"])\n",
    "        base[\"procedure_LoS_Std\"] = base[PROC_COL].map(proc_stats[\"std\"])\n",
    "\n",
    "    order = [\n",
    "        \"eid\",\n",
    "        \"vdate\",\n",
    "        \"lengthofstay\",\n",
    "        \"lengthofstay_Pred\",\n",
    "        \"lengthofstay_Pred_Rounded\",\n",
    "        \"discharged_Pred\",\n",
    "    ]\n",
    "    if PROC_COL and PROC_COL in base.columns:\n",
    "        order.append(PROC_COL)\n",
    "        order += [\"procedure_AvgLoS\", \"procedure_LoS_Std\"]\n",
    "    order += [c for c in present_cols if c not in order]\n",
    "    cols_final = [c for c in order if c in base.columns]\n",
    "    return base[cols_final]\n",
    "\n",
    "\n",
    "out_dir_preds = Path(\"./predictions_sklearn_los\")\n",
    "out_dir_preds.mkdir(parents=True, exist_ok=True)\n",
    "for key in [\"GBT_40\", \"RF_100\", \"LIN_OLS\"]:\n",
    "    if key in fitted_pipelines:\n",
    "        tbl = build_predictions_table(key)\n",
    "        tbl.to_csv(out_dir_preds / f\"LoS_Predictions_{key}.csv\", index=False)\n",
    "\n",
    "print(f\"Prediction tables written to {out_dir_preds.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ayiyang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
